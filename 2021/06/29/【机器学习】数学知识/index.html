<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="1EB8XoOl0C"><meta name="google-site-verification" content="K7thEgdLm0UfRWJ5MGdF7sCcjClSzAlxFLPv2Oz5CGM"><title> ⭐️机器学习中的数学知识 · Hexo</title><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="⭐️机器学习中的数学知识 - John Doe"><meta name="keywords"><meta name="author" content="John Doe"><link rel="short icon" href="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/favicon.ico"><link rel="stylesheet" href="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/bubuzou.css"><link rel="search" type="application/opensearchdescription+xml" href="http://example.com/atom.xml" title="Hexo"><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body><header><div class="header row"> <a href="/" class="logo-link"><img src="https://simg.nicepng.com/png/small/31-311776_royal…-free-collection-of-free-chipmunk-download-on.png"></a><ul id="nav_list" class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" data-hover="博文" class="nav-list-link">博文</a></li><li class="nav-list-item"><a href="/archives/" target="_self" data-hover="归档" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/about/" target="_self" data-hover="关于" class="nav-list-link">关于</a></li></ul><div class="search"><a id="search_btn" href="#search"></a></div><div id="nav_btn" class="nav-btn"><span></span><span></span><span></span></div></div></header><div class="row scroll-con"><section class="container"><!-- for archive page--><div id="postAr" class="post"><article class="post-block"><h1 class="post-title">⭐️机器学习中的数学知识</h1><div class="post-info">2021-06-29</div><div class="post-content"><span id="more"></span>



<h2 id="概率、统计区别"><a href="#概率、统计区别" class="headerlink" title="概率、统计区别"></a>概率、统计区别</h2><p><a target="_blank" rel="noopener" href="https://www.sohu.com/a/260383068_464088">概率论与统计学的关系是什么？ </a></p>
<p>概率论就好比是给你一个模型，你可以知道这个模型会产生什么样的数据；</p>
<p>而统计则是给你一些数据，你来判断是由什么样的模型产生的。</p>
<p>如下图：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs2a76yjkxj30b408cq3b.jpg" alt="概率统计区别"></p>
<p>Lary Wasserman 在 《All of Statistics》 的序言里有说过概率论和统计推断的区别：</p>
<blockquote>
<p>1）The basic problem of statistical inference is the inverse of probability:Given the outcomes, what can we say about the process that generated the data?</p>
<p>2）The basic problem that we study in probability is: Given a data generating process, what are the properities of the outcomes?</p>
</blockquote>
<h2 id="概率"><a href="#概率" class="headerlink" title="概率"></a>概率</h2><h3 id="蒲丰投针"><a href="#蒲丰投针" class="headerlink" title="蒲丰投针"></a>蒲丰投针</h3><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gsc2ajvg1pj31os0u01kz.jpg"></p>
<p>模拟：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">针长a, 线间距d, a&lt;d</span></span><br><span class="line"><span class="string">针中点M 到最近的线距离为：x∈[0，d/2]</span></span><br><span class="line"><span class="string">针与线的夹角为 alpha ∈[0,pi]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">相交条件：x&lt;a*sin(alpha)/2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">throw_needle</span>(<span class="params">n, a, d=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;布丰投针试验</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param n: 投针试验次数</span></span><br><span class="line"><span class="string">    :param a: 针长度</span></span><br><span class="line"><span class="string">    :param d: 1</span></span><br><span class="line"><span class="string">    :return: pi 的估计值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    alpha = np.random.uniform(<span class="number">0</span>, np.pi, n)</span><br><span class="line">    x = np.random.uniform(<span class="number">0</span>, d/<span class="number">2</span>, n)</span><br><span class="line">    m = np.<span class="built_in">sum</span>(x &lt; a*np.sin(alpha)/<span class="number">2</span>)  <span class="comment"># 相交，【不进行循环，直接利用numpy的性质，计算速度会更快】</span></span><br><span class="line">    pi = <span class="number">2</span>*a*n/d/m</span><br><span class="line">    <span class="keyword">return</span> pi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">prob = throw_needle(<span class="number">10</span>**<span class="number">8</span>, <span class="number">0.8</span>)</span><br><span class="line"><span class="built_in">print</span>(prob)</span><br><span class="line"><span class="number">3.141567658362057</span></span><br></pre></td></tr></table></figure>



<h3 id="大数定理"><a href="#大数定理" class="headerlink" title="大数定理"></a>大数定理</h3><p>定义参考：陈希孺《概率论与数理统计》p142</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grzjsoax1vj30ys0nmq8q.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grzjokxpxdj30xw0u0gzz.jpg"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/flitdu/consult/blob/main/jupyter/%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86%E4%B8%BE%E4%BE%8B.ipynb">代码展示</a></li>
</ul>
<p>以筛子为例，假设有1000万的筛子点数随机样本，然后，通过随机抽样，估计总体的均值情况：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grzk9qi6mzj312k0k2dhc.jpg"></p>
<h3 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h3><blockquote>
<p>在概率论上，习惯于把和的分布收敛于正态分布的那一类定理都叫’中心极限定理‘</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grzjy1totij30u00vl7f6.jpg"></p>
<ul>
<li>应用</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grzjyquvjij311a0fwdlp.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grzjz3wykdj31000lmtf3.jpg"></p>
<h2 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h2><p>视频参考：【1】</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs14i6fqkuj317a0u07wi.jpg"></p>
<p>大量的独立事件相加，就成为了一种社会现象</p>
<h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grzi8hg5bwj31gk0ogafa.jpg"></p>
<h3 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h3><p>概率分布描述的对象是数据，数据分为两种：</p>
<p>1）连续型数据</p>
<p>2）离散型数据</p>
<p>分布，指的是数据在统计图中的形状</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs14tw5pvlj30zm0ky7vo.jpg"></p>
<h3 id="分布类型"><a href="#分布类型" class="headerlink" title="分布类型"></a>分布类型</h3><table>
<thead>
<tr>
<th>离散概率分布</th>
<th>连续概率分布</th>
</tr>
</thead>
<tbody><tr>
<td>伯努利分布，又叫<strong>0-1分布</strong></td>
<td>正态分布</td>
</tr>
<tr>
<td>二项分布</td>
<td><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%CE%B2%E5%88%86%E5%B8%83/22787190">β分布</a></td>
</tr>
<tr>
<td>几何分布</td>
<td>指数分布</td>
</tr>
<tr>
<td>泊松分布</td>
<td>Gamma分布</td>
</tr>
</tbody></table>
<ul>
<li>0-1分布</li>
</ul>
<p>分布律为：$$p(X=k)=p^k(1-p)^{1-k}$$</p>
<p>其中<code>k=0,1,0&lt;p&lt;1</code></p>
<p>使用场景：抛硬币、新生儿的性别登记、检查产品质量是否合格等</p>
<ul>
<li>泊松分布</li>
</ul>
<p>分布律为：$$p(X=k)=\frac{\lambda ^{k}e^{-\lambda}}{k!}$$</p>
<p>其中， <code>λ为均值，k=0,1,2.....</code></p>
<p>用来描述不寻常事情发生的概率，如一周内赢彩票人数，某地区一天内邮递遗失的信件数等</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs40i7hk0dj30v60kejx9.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># p(X=k)=\frac&#123;\lambda ^&#123;k&#125;e^&#123;-\lambda&#125;&#125;&#123;k!&#125;</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">poisson = <span class="keyword">lambda</span> lam,k:(lam**k*math.exp(-lam))/math.factorial(k)</span><br><span class="line">poisson(<span class="number">0.1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">x= [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">21</span>)]</span><br><span class="line">y1= [poisson(<span class="number">2.5</span>,i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y2= [poisson(<span class="number">5</span>,i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y3= [poisson(<span class="number">10</span>,i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"></span><br><span class="line">plt.plot(x,y1,<span class="string">&#x27;-o&#x27;</span>, label=<span class="string">&#x27;lambda=2.5&#x27;</span>)</span><br><span class="line">plt.plot(x,y2,<span class="string">&#x27;-o&#x27;</span>, label=<span class="string">&#x27;lambda=5&#x27;</span>)</span><br><span class="line">plt.plot(x,y3,<span class="string">&#x27;-o&#x27;</span>, label=<span class="string">&#x27;lambda=10&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>如下图，某个公交站每小时平均有三辆车，可以用泊松分布得到一小时内等到不同数量车的概率</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs1su553fnj30y40m0x2w.jpg"></p>
<ul>
<li>正态分布</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83">正态分布</a>下，和平均值偏离一个标准差以内的数据会占68.27%，偏离二个标准差以内的数据会到95.45%，偏离三个标准差以内的数据会到99.73%。</p>
<p>这也就是<strong>68–95–99.7法则</strong>（68–95–99.7 rule）</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Empirical_Rule.PNG/450px-Empirical_Rule.PNG"></p>
<h2 id="贝叶斯决策"><a href="#贝叶斯决策" class="headerlink" title="贝叶斯决策"></a>贝叶斯决策</h2><p>（1）已知类条件概率密度参数表达式和先验概率</p>
<p>（2）利用贝叶斯公式转成后验概率</p>
<p>（3）根据后验概率大小进行决策分类</p>
<h2 id="马尔科夫链"><a href="#马尔科夫链" class="headerlink" title="马尔科夫链"></a>马尔科夫链</h2><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gsc3fllx9lj31e2080q4s.jpg"></p>
<p>马尔科夫链是满足马尔科夫性质的随机过程。</p>
<p>马尔科夫链<code>X1,X2,...</code>描述了一个状态序列，其中每个状态值取决于前一个状态。<code>X_t</code>为随机变量，称为时刻t 的状态，其取值范围称为状态空间。</p>
<p>马尔科夫链的数学定义为：</p>
<p>$$P(X_{t+1}|X_1,X_2,…X_t-1,X_t) = P(X_{t+1}|X_t)$$</p>
<ul>
<li>举例</li>
</ul>
<p>社会学家把人按照经济状况分成三类：下层、中层、上层。用状态 <code>1,2,3</code> 代表着三个阶层。社会学家发现：决定一个人的收入阶层的最重要因素就是其父母的收入阶层。</p>
<p>1）如果一个人的收入属于下层，则他的孩子属于下层的概率是 0.65，属于中层的概率是 0.28，属于上层的概率是 0.07 。</p>
<p>2）如果一个人的收入属于中层，则他的孩子属于下层的概率是 0.15，属于中层的概率是 0.67，属于上层的概率是 0.18 。</p>
<p>3）如果一个人的收入属于上层，则他的孩子属于下层的概率是 0.12，属于中层的概率是 0.36，属于上层的概率是 0.52 。</p>
<p>从父代到子代，收入阶层的变化的转移概率如下：</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">子代阶层1</th>
<th align="center">子代阶层2</th>
<th align="center">子代阶层3</th>
</tr>
</thead>
<tbody><tr>
<td align="center">父代阶层1</td>
<td align="center">0.65</td>
<td align="center">0.28</td>
<td align="center">0.07</td>
</tr>
<tr>
<td align="center">父代阶层2</td>
<td align="center">0.15</td>
<td align="center">0.67</td>
<td align="center">0.18</td>
</tr>
<tr>
<td align="center">父代阶层3</td>
<td align="center">0.12</td>
<td align="center">0.36</td>
<td align="center">0.52</td>
</tr>
</tbody></table>
<p>假设初始概率分布为 ，给出前 14 代人的分布状况：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">c1: 下层</span></span><br><span class="line"><span class="string">c2：中层</span></span><br><span class="line"><span class="string">c3: 上层</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> numpy.matlib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">0.72</span>,<span class="number">0.19</span>,<span class="number">0.09</span>])</span><br><span class="line">b = np.array([<span class="number">0.65</span>,<span class="number">0.15</span>,<span class="number">0.12</span>])</span><br><span class="line"><span class="built_in">print</span>(np.dot(a,b))</span><br><span class="line">c1 = []</span><br><span class="line">c2= []</span><br><span class="line">c3= []</span><br><span class="line"></span><br><span class="line">pi = np.array([<span class="number">0.09</span>,<span class="number">0.19</span>,<span class="number">0.72</span>])  <span class="comment"># 初始概率</span></span><br><span class="line">A= np.array([[<span class="number">0.65</span>,<span class="number">0.28</span>,<span class="number">0.07</span>],[<span class="number">0.15</span>,<span class="number">0.67</span>,<span class="number">0.18</span>],[<span class="number">0.12</span>,<span class="number">0.36</span>,<span class="number">0.52</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;第<span class="subst">&#123;<span class="number">0</span>&#125;</span>代：<span class="subst">&#123;pi&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">15</span>):</span><br><span class="line">    c1.append(pi[<span class="number">0</span>])</span><br><span class="line">    c2.append(pi[<span class="number">1</span>])</span><br><span class="line">    c3.append(pi[<span class="number">2</span>])</span><br><span class="line">    pi = np.dot(pi, A)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;第<span class="subst">&#123;i&#125;</span>代：<span class="subst">&#123;pi&#125;</span>&#x27;</span>)</span><br><span class="line">c1,c2,c3</span><br><span class="line">plt.plot(c1,marker=<span class="string">&#x27;o&#x27;</span>,label=<span class="string">&#x27;c1-low&#x27;</span>)</span><br><span class="line">plt.plot(c2,marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;c2-mid&#x27;</span>)</span><br><span class="line">plt.plot(c3,marker=<span class="string">&#x27;o&#x27;</span>,label=<span class="string">&#x27;c3-upper&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">0.5073</span><br><span class="line">第0代：[0.09 0.19 0.72]</span><br><span class="line">第1代：[0.1734 0.4117 0.4149]</span><br><span class="line">第2代：[0.224253 0.473755 0.301992]</span><br><span class="line">第3代：[0.25306674 0.48892381 0.25800945]</span><br><span class="line">第4代：[0.26879309 0.49132104 0.23988587]</span><br><span class="line">第5代：[0.27719997 0.49080608 0.23199396]</span><br><span class="line">第6代：[0.28164016 0.48997389 0.22838595]</span><br><span class="line">第7代：[0.2839685  0.48936069 0.2266708 ]</span><br><span class="line">第8代：[0.28518413 0.48898433 0.22583154]</span><br><span class="line">第9代：[0.28581712 0.48877041 0.22541247]</span><br><span class="line">第10代：[0.28614618 0.48865346 0.22520036]</span><br><span class="line">第11代：[0.28631708 0.48859088 0.22509204]</span><br><span class="line">第12代：[0.28640578 0.48855781 0.22503641]</span><br><span class="line">第13代：[0.2864518  0.48854046 0.22500775]</span><br><span class="line">第14代：[0.28647567 0.4885314  0.22499294]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gscw4xrkjcj310y0g20vj.jpg"></p>
<p>从图上看出，初始概率<code>[0.09,0.19,0.72]</code> ，经过三代后，变为<code>[0.25306674 0.48892381 0.25800945]</code>，也就是将变为中层。这就是经常说的 ‘富不过三代’ ？</p>
<p>如果，每一代都对教育很重视，在下一代培养上进行了投入，提高进入上层的几率，那么曲线图会发生变化如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gsczkoxr2dj314c0gmtcx.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">c1: 下层</span></span><br><span class="line"><span class="string">c2：中层</span></span><br><span class="line"><span class="string">c3: 上层</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> numpy.matlib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">0.72</span>,<span class="number">0.19</span>,<span class="number">0.09</span>])</span><br><span class="line">b = np.array([<span class="number">0.65</span>,<span class="number">0.15</span>,<span class="number">0.12</span>])</span><br><span class="line"><span class="built_in">print</span>(np.dot(a,b))</span><br><span class="line">c1 = []</span><br><span class="line">c2= []</span><br><span class="line">c3= []</span><br><span class="line">c1_ = []</span><br><span class="line">c2_= []</span><br><span class="line">c3_= []</span><br><span class="line">pi = np.array([<span class="number">0.09</span>,<span class="number">0.19</span>,<span class="number">0.72</span>])  <span class="comment"># 初始概率</span></span><br><span class="line">pi_ = pi</span><br><span class="line"></span><br><span class="line">A= np.array([[<span class="number">0.65</span>,<span class="number">0.28</span>,<span class="number">0.07</span>],[<span class="number">0.15</span>,<span class="number">0.67</span>,<span class="number">0.18</span>],[<span class="number">0.12</span>,<span class="number">0.36</span>,<span class="number">0.52</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;第<span class="subst">&#123;<span class="number">0</span>&#125;</span>代：<span class="subst">&#123;pi&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">15</span>):</span><br><span class="line">    c1.append(pi[<span class="number">0</span>])</span><br><span class="line">    c2.append(pi[<span class="number">1</span>])</span><br><span class="line">    c3.append(pi[<span class="number">2</span>])</span><br><span class="line">    pi = np.dot(pi, A)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;第<span class="subst">&#123;i&#125;</span>代：<span class="subst">&#123;pi&#125;</span>&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#     添加受教育，提高进入上层的概率</span></span><br><span class="line">    c1_.append(pi_[<span class="number">0</span>])</span><br><span class="line">    c2_.append(pi_[<span class="number">1</span>])</span><br><span class="line">    c3_.append(pi_[<span class="number">2</span>])</span><br><span class="line">    pi_ = pi_+np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.3</span>])</span><br><span class="line">    pi_ = pi_/<span class="built_in">sum</span>(pi_)</span><br><span class="line">    pi_ = np.dot(pi_, A)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;受教育，第<span class="subst">&#123;i&#125;</span>代：<span class="subst">&#123;pi_&#125;</span>&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">c1,c2,c3</span><br><span class="line">plt.plot(c1,marker=<span class="string">&#x27;o&#x27;</span>,label=<span class="string">&#x27;c1-low&#x27;</span>)</span><br><span class="line">plt.plot(c2,marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;c2-mid&#x27;</span>)</span><br><span class="line">plt.plot(c3,marker=<span class="string">&#x27;o&#x27;</span>,label=<span class="string">&#x27;c3-upper&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(c1_,marker=<span class="string">&#x27;*&#x27;</span>,linestyle=<span class="string">&quot;-.&quot;</span>, label=<span class="string">&#x27;edu-low&#x27;</span>,color = <span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(c2_,marker=<span class="string">&#x27;*&#x27;</span>, linestyle=<span class="string">&quot;-.&quot;</span>, label=<span class="string">&#x27;edu-mid&#x27;</span>,color = <span class="string">&#x27;orange&#x27;</span>)</span><br><span class="line">plt.plot(c3_,marker=<span class="string">&#x27;*&#x27;</span>,linestyle=<span class="string">&quot;-.&quot;</span>,label=<span class="string">&#x27;edu-upper&#x27;</span>,color = <span class="string">&#x27;green&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>值得注意的是，纯理想的情况下，最终的收敛行为由概率转移矩阵 A 决定。也就是大环境</p>
<p>如果社会大环境上升渠道关闭（比如封建社会末期那样），那么下层的人士就很难在进入上层了。</p>
<p>比如，修改A为<code>A= np.array([[0.95,0.03,0.02],[0.15,0.67,0.18],[0.12,0.36,0.52]])</code>：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gsczpo3592j30x00gggpj.jpg"></p>
<p>当然，这只是一个简单的模拟。真实的社会情况，远比这个要复杂。</p>
<h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><h3 id="自信息"><a href="#自信息" class="headerlink" title="自信息"></a>自信息</h3><p>描述一个事件所含的信息量</p>
<p><strong>自信息</strong>的期望值就是信息论中的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)">熵</a>，它反映了随机变量采样时的平均不确定程度。</p>
<p>由定义，当信息被拥有它的实体传递给接收它的实体时，仅当接收实体不知道信息的先验知识时信息才得到传递。如果接收实体事先知道了消息的内容，这条消息所传递的信息量就是0。只有当接收实体对消息对先验知识少于100%时，消息才真正传递信息。</p>
<ul>
<li>自信息计算：<code>I(x)=-log(P(x))</code></li>
<li>熵H(X)：</li>
</ul>
<p>实际上，求的是关于信息量的概率期望</p>
<p>$$H(x) = \sum_{i}P(x_i)I(x_i)= -\sum_{i}P(x_i)\log(P(x_i))$$</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs46rl51bvj615u0ju45b02.jpg"></p>
<h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wangguchangqing/p/12068084.html">一文搞懂交叉熵损失</a><br>$$<br>H(p,q) = -\sum_x^{} p(x)log q(x)<br>$$<br>其中p为真实分布，q为非真实分布。交叉熵越低，意味着q越接近p。所以在机器学习分类算法中，我们总是最小化交叉熵，交叉熵越低，间接证明算法推算出的非真实分布q越接近真实分布p。</p>
<ul>
<li>相对熵D_KL</li>
</ul>
<p>表示同一个随机变量的两个不同分布间的距离（1951年提出）</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs6gqm25rnj310u04owf5.jpg"></p>
<p>相对熵具有以下性质：</p>
<ul>
<li>如果p(x),q(x)分布相同，则其相对熵=0</li>
<li>$D_{KL}(p||q)\neq D_{KL}(q||p)$，即相对熵不具有对称性</li>
<li>$D_{KL}(p||q)\geqslant 0$</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs486zrkdtj310206eq3s.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs480exk50j317a0j8tb3.jpg"></p>
<blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs484vv26kj31l606q40v.jpg" alt="image-20210704002541376"></p>
</blockquote>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>对于一维张量，也就是向量，常引入<strong>范数</strong>的概念：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/35897775">向量范数与矩阵范数</a></p>
<ul>
<li><strong>p-范数</strong></li>
</ul>
<p>$$\left | x \right |_p = (\sum |x_i|^{p})^\frac{1}{p}$$</p>
<p>注意，一些特殊范数：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs539bq10mj31100hkwgc.jpg" alt="image-20191127001638381"></p>
<ul>
<li>机器学习中应用</li>
</ul>
<p>优化目标中一般会加入参数的L范数，也就是正则化项。选择合适的𝜆超参数可以获得较好的训练性能，同时保证网络的<strong>稀疏性</strong>，从而获得不错的泛化能力。</p>
<p>如下图，为不同程度的正则化约束对网络权值的影响【龙书】</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gtbddjo6bqj30uk0cudgw.jpg" alt="image-20210810080613185"></p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gtbdb3djxjj311h0u0dl0.jpg" alt="image-20210810080348994"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/s/video/BV1TJ411y7Mp">统计的乐趣</a><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs3o3tsx6hj318x0u07wh.jpg" alt="image-20210703125238027"></li>
<li></li>
</ol>
</div></article></div><div class="right-container"><div class="widget"><div id="arAnchorBar"></div></div></div></section></div><div class="right-menu"></div><div class="modal search-modal"><div class="input-field"><input type="text" id="search_input"><label for="search-input">搜索</label></div><div id="search_result" class="search-result"></div></div><div class="blog-overlay"></div><footer class="row"><div class="footer-con"><div class="paginator"><a href="/2021/07/20/TF%E5%AD%A6%E4%B9%A0/" title="⭐️TensorFlow 学习" class="prev">PREV</a><a href="/2021/06/06/bert%E6%BA%90%E7%A0%81%E7%90%86%E8%A7%A3/" title="⭐️bert源码理解" class="next">NEXT</a></div><div class="copyright"><p>© 2016 - 2021 <a target="_blank">John Doe</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <br> and <a href="https://github.com/Bulandent/hexo-theme-bubuzou" target="_blank">hexo-theme-bubuzou</a></p><p> <span style="padding-right: 6px;">闽ICP备16007301号-2</span></p></div><div class="totop"><i></i></div></div></footer><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/jquery-1.8.2.min.js"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/articleCatalog.js"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/main.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>