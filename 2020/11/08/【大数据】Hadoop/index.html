<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="1EB8XoOl0C"><meta name="google-site-verification" content="K7thEgdLm0UfRWJ5MGdF7sCcjClSzAlxFLPv2Oz5CGM"><title> ⭐️Hadoop · Hexo</title><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="⭐️Hadoop - John Doe"><meta name="keywords"><meta name="author" content="John Doe"><link rel="short icon" href="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/favicon.ico"><link rel="stylesheet" href="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/bubuzou.css"><link rel="search" type="application/opensearchdescription+xml" href="http://example.com/atom.xml" title="Hexo"><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body><header><div class="header row"> <a href="/" class="logo-link"><img src="/images/logo.png"></a><ul id="nav_list" class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" data-hover="博文" class="nav-list-link">博文</a></li><li class="nav-list-item"><a href="/archives/" target="_self" data-hover="归档" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/about/" target="_self" data-hover="关于" class="nav-list-link">关于</a></li></ul><div class="search"><a id="search_btn" href="#search"></a></div><div id="nav_btn" class="nav-btn"><span></span><span></span><span></span></div></div></header><div class="row scroll-con"><section class="container"><!-- for archive page--><div id="postAr" class="post"><article class="post-block"><h1 class="post-title">⭐️Hadoop</h1><div class="post-info">2020-11-08</div><div class="post-content"><h2 id="Hadoop-生态"><a href="#Hadoop-生态" class="headerlink" title="Hadoop 生态"></a>Hadoop 生态</h2><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/jVnDpgXqRqVBWv0UG_1OBA">深入浅出大数据：到底什么是Hadoop？</a></p>
<p>hadoop 基本组件包括：HDFS, MapReduce, Yarn</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gu61gm6civj61ga0p279j02.jpg" alt="image-20210905204634103"></p>
<blockquote>
<p>DAG: 有向无环图，Directed Acyclic  Graph</p>
<p>Pig: 接近脚本的方式去描述MR</p>
<p>Hive: 用的是SQL，SQL–&gt;JAVA–&gt;MR</p>
<p>Hbase: kv store，非常适合用来进行<strong>大数据的实时查询</strong></p>
<p>Zookeeper: 高一致性的分布存取协同系统</p>
</blockquote>
<p>大数据技术体系，虽然各种技术百花齐放，层出不穷，但大数据技术本质上无非解决4个核心问题：</p>
<blockquote>
<ol>
<li><strong>存储，</strong>海量的数据怎样有效的存储？主要包括<strong>hdfs</strong>、Kafka；</li>
<li><strong>计算，</strong>海量的数据怎样快速计算？主要包括<strong>MapReduce</strong>、Spark、Flink等；</li>
<li><strong>查询，</strong>海量数据怎样快速查询？主要为Nosql和Olap，Nosql主要包括<strong>Hbase</strong>、 Cassandra 等，其中olap包括kylin、impla等，其中Nosql主要解决随机查询，Olap技术主要解决关联查询；</li>
<li><strong>挖掘，</strong>海量数据怎样挖掘出隐藏的知识？也就是当前火热的机器学习和深度学习等技术，包括TensorFlow、caffe、mahout等；</li>
</ol>
</blockquote>
<p>一般来说，数据包括两种：业务数据和日志数据</p>
<p>1）业务数据就是数据库中的结构性的数据，规规整整。</p>
<p>可以通过Sqoop进行导入，比如一张表，数据少的话，每天我把表全部导入一遍，这叫<strong>全量同步</strong>；数据特别大，就只同步每天变化和新增的 ，这是<strong>增量同步</strong></p>
<p>对应的是离线分析</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gu4u9uufl1j60t008474n02.jpg" alt="image-20210904195217405"></p>
<p>在大数据架构中，Hive和HBase是<strong>协作关系</strong>，数据流一般如下图：</p>
<ol>
<li>通过ETL工具将数据源抽取到HDFS存储；</li>
<li>通过Hive清洗、处理和计算原始数据；</li>
<li>HIve清洗处理后的结果，如果是面向海量数据随机查询场景的可存入Hbase</li>
<li>数据应用从HBase查询数据；</li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gu5hb8114ij61400b23zb02.jpg" alt="img"></p>
<p>2）准实时处理</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gu4xhpcbhlj614k08ijs902.jpg" alt="image-20210904214336869"></p>
<p>离线数据是等半夜数据都抽到Hive 中再计算，而Spark Streaming 则是实时数据来一小批，它就处理一小批。</p>
<p>从本质上讲，spark streaming还是批处理，只不过是每一批数据很少，并且处理很及时，从而达到实时计算的目的。</p>
<blockquote>
<p>spark 是一整套组件的统称，比如你可以用 JAVA写Spark 任务，用Spark SQL  去写SQL，可以用 Spark MLib 完成机器学习的模型训练等</p>
</blockquote>
<p>3）Flink实时处理</p>
<p>一条一条数据处理</p>
<p>Hadoop的应用非常广泛，包括：<strong>搜索、日志处理、推荐系统、数据分析、视频图像分析、数据保存等</strong>，都可以使用它进行部署。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/407175099">大数据技术漫谈 ——从Hadoop、Storm、Spark、HBase到Hive、Flink、Lindorm</a></p>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><ul>
<li>zookeeper</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master zookeeper-3.4.9]# bin/zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>对应进程：</p>
<p>15936 <strong>QuorumPeerMain</strong></p>
<ul>
<li>hadoop</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop-2.7.5]# sbin/start-dfs.sh</span><br><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>

<p>15746 SecondaryNameNode<br>15466 NameNode<br>15936 QuorumPeerMain<br>15565 DataNode<br>15974 Jps</p>
<ul>
<li>三个端口查看界面</li>
</ul>
<p> <a target="_blank" rel="noopener" href="http://node01:50070/explorer.html#/">http://node01:50070/explorer.html#/</a> 查看hdfs </p>
<p><a target="_blank" rel="noopener" href="http://node01:8088/cluster">http://node01:8088/cluster</a> 查看yarn集群</p>
<p> <a target="_blank" rel="noopener" href="http://node01:19888/jobhistory">http://node01:19888/jobhistory</a> 查看历史完成的任务</p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><ul>
<li>架构</li>
</ul>
<p>NameNode,  DataNode, client</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gu607g65r2j60to0di75502.jpg" alt="image-20210905200307460"></p>
<blockquote>
<p><strong>NameNode：</strong>是Master节点（主节点），可以看作是分布式文件系统中的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。NameNode会将文件系统的Meta-data存储在内存中，这些信息主要包括了文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode的信息等。</p>
<p><strong>DataNode：</strong>是Slave节点（从节点），是文件存储的基本单元，它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。</p>
<p><strong>Client：</strong>切分文件；访问HDFS；与NameNode交互，获得文件位置信息；与DataNode交互，读取和写入数据。 </p>
<p>还有一个<strong>Block（块）</strong>的概念：Block是HDFS中的基本读写单元；HDFS中的文件都是被切割为block（块）进行存储的；这些块被复制到多个DataNode中；块的大小（通常为64MB）和复制的块数量在创建文件时由Client决定。</p>
</blockquote>
<ul>
<li>HDFS 写入过程</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gu60bz12g9j61180hedi102.jpg" alt="image-20210905200730642"></p>
<blockquote>
<p>1 用户向Client（客户机）提出请求。例如，需要写入200MB的数据。</p>
<p>2 Client制定计划：将数据按照64MB为块，进行切割；所有的块都保存三份。</p>
<p>3 Client将大文件切分成块（block）。</p>
<p>4 针对第一个块，Client告诉NameNode（主控节点），请帮助我，将64MB的块复制三份。</p>
<p>5 NameNode告诉Client三个DataNode（数据节点）的地址，并且将它们根据到Client的距离，进行了排序。</p>
<p>6 Client把数据和清单发给第一个DataNode。</p>
<p>7 第一个DataNode将数据复制给第二个DataNode。</p>
<p>8 第二个DataNode将数据复制给第三个DataNode。</p>
<p>9 如果某一个块的所有数据都已写入，就会向NameNode反馈已完成。</p>
<p>10 对第二个Block，也进行相同的操作。</p>
<p>11 所有Block都完成后，关闭文件。NameNode会将数据持久化到磁盘上。</p>
</blockquote>
<ul>
<li>hdfs读取过程</li>
</ul>
<p>可以并行读</p>
<p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1glzeffq23kj31rg0tu4qq.jpg" alt="image-20201225001319996"></p>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>核心步骤包括两部分：Map（映射）和Reduce（归约）</p>
<p>当你向MapReduce框架提交一个计算作业时，它会首先把计算作业拆分成若干个<strong>Map任务</strong>，然后分配到不同的节点上去执行，每一个Map任务处理输入数据中的一部分，当Map任务完成后，它会生成一些中间文件，这些中间文件将会作为<strong>Reduce任务</strong>的输入数据。Reduce任务的主要目标就是把前面若干个Map的输出汇总到一起并输出。</p>
<p>举例：</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gu617zaoxpj61cm0sc7aw02.jpg" alt="[Hadoop In 5 Minutes | What Is Hadoop? | Introduction To Hadoop | Hadoop Explained |Simplilearn](https://www.youtube.com/watch?v=aReuLtY0YMI&amp;ab_channel=Simplilearn)"></p>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p><a target="_blank" rel="noopener" href="https://github.com/HelloGitHub-Team/HelloZooKeeper">HelloZooKeeper</a></p>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/2089271c15940432788af153be7ac6ac101c761c8f3fa8cad3d24cdf9f961c9e/68747470733a2f2f63646e2e6265656b6b612e636f6d2f626c6f67696d672f61737365742f3230323130342f6267323032313034323531302e6a7067"><img src="https://camo.githubusercontent.com/2089271c15940432788af153be7ac6ac101c761c8f3fa8cad3d24cdf9f961c9e/68747470733a2f2f63646e2e6265656b6b612e636f6d2f626c6f67696d672f61737365742f3230323130342f6267323032313034323531302e6a7067" alt="img"></a></p>
<p>ZooKeeper 的中文教程，从最基础的安装使用到背后原理和源码，使用有趣诙谐的文字讲解。ZooKeeper 是大型分布式计算的配置服务工具。</p>
<h2 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h2><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1grcdrjhi9gj31ky0og4df.jpg" alt="image-20210609222438603"></p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1680595">Kettle构建Hadoop ETL实践（一）：ETL与Kettle</a></p>
<h2 id="scala"><a href="#scala" class="headerlink" title="scala"></a>scala</h2><p>安装：</p>
<ul>
<li>On macOS you can also use <a target="_blank" rel="noopener" href="https://brew.sh/">Homebrew</a> and existing <a target="_blank" rel="noopener" href="https://formulae.brew.sh/formula/scala">Scala Formulae</a><br><code>brew update</code><br><code>brew install scala</code></li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>B站<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ek4y117Yq?p=59">自学教程 ｜Hadoop从零到精通完整版</a></li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gu4r7tku38j61ln0u0wku02.jpg" alt="image-20210904180632497"></p>
<ol start="2">
<li><a target="_blank" rel="noopener" href="http://c.biancheng.net/view/3500.html">http://c.biancheng.net/view/3500.html</a></li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gqcmextws3j31ie0u0hdu.jpg" alt="image-20210510000331635"></p>
<ol>
<li></li>
</ol>
</div></article></div><div class="right-container"><div class="widget"><div id="arAnchorBar"></div></div></div></section></div><div class="right-menu"></div><div class="modal search-modal"><div class="input-field"><input type="text" id="search_input"><label for="search-input">搜索</label></div><div id="search_result" class="search-result"></div></div><div class="blog-overlay"></div><footer class="row"><div class="footer-con"><div class="paginator"><a href="/2020/11/13/labuladong%E6%96%87%E7%AB%A0%E6%A0%87%E9%A2%98%E5%8F%8A%E9%93%BE%E6%8E%A5/" title="⭐️labuladong文章标题及链接" class="prev">PREV</a><a href="/2020/07/25/%E7%AE%80%E5%8E%86%E6%80%9D%E8%80%83/" title="⭐️简历思考" class="next">NEXT</a></div><div class="copyright"><p>© 2016 - 2021 <a target="_blank">John Doe</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <br> and <a href="https://github.com/Bulandent/hexo-theme-bubuzou" target="_blank">hexo-theme-bubuzou</a></p><p> <span style="padding-right: 6px;">闽ICP备16007301号-2</span></p></div><div class="totop"><i></i></div></div></footer><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/jquery-1.8.2.min.js"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/articleCatalog.js"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/main.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>