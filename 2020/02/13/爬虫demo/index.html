<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>⭐️爬虫demo | Note</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="[TOC] 这是摘要……">
<meta name="keywords" content="爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="⭐️爬虫demo">
<meta property="og:url" content="http://yoursite.com/2020/02/13/爬虫demo/index.html">
<meta property="og:site_name" content="Note">
<meta property="og:description" content="[TOC] 这是摘要……">
<meta property="og:locale" content="zh-CN//语言">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbusg75nh1j315x0u0qg6.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbusafady3j31b10u0ap7.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbusx4qs54j30z60kwtb5.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbuswhvdp8j31b60u0wpi.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbuolctv9bj31kb0u01ky.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbupbmdqphj31w00u01kx.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbus4brqjhj31j50u0kjl.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbus6080v8j31a20pste2.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbykx045klj31bv0u0dlt.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbykzclomaj31wi0ryguh.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggve7hpqjqj31r10u01ky.jpg">
<meta property="og:updated_time" content="2021-02-27T06:19:38.893Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="⭐️爬虫demo">
<meta name="twitter:description" content="[TOC] 这是摘要……">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/0082zybpgy1gbusg75nh1j315x0u0qg6.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Note" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Note</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-爬虫demo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/13/爬虫demo/" class="article-date">
  <time datetime="2020-02-12T16:00:00.000Z" itemprop="datePublished">2020-02-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/网页/">网页</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      ⭐️爬虫demo
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>[TOC]</p>
<p>这是摘要……</p>
<a id="more"></a>

<h2 id="☆GitHub爬虫教程"><a href="#☆GitHub爬虫教程" class="headerlink" title="☆GitHub爬虫教程"></a>☆GitHub爬虫教程</h2><p><a href="https://github.com/wistbean/learn_python3_spider" target="_blank" rel="noopener">https://github.com/wistbean/learn_python3_spider</a></p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbusg75nh1j315x0u0qg6.jpg" alt="image-20200213150732293"></p>
<h2 id="豆瓣电影-Top-250【1】"><a href="#豆瓣电影-Top-250【1】" class="headerlink" title="豆瓣电影 Top 250【1】"></a>豆瓣电影 Top 250【1】</h2><p><a href="https://movie.douban.com/top250" target="_blank" rel="noopener">https://movie.douban.com/top250</a>?</p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbusafady3j31b10u0ap7.jpg" alt="image-20200213150159409"></p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbusx4qs54j30z60kwtb5.jpg" alt="image-20200213152348592"></p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbuswhvdp8j31b60u0wpi.jpg" alt="image-20200213152311755"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ua = UserAgent()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_douban</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: ua.chrome&#125;</span><br><span class="line">        response = requests.get(url,headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(soup)</span>:</span></span><br><span class="line">    list = soup.find(class_=<span class="string">'grid_view'</span>).find_all(<span class="string">'li'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> list:</span><br><span class="line">        item_img = item.find(<span class="string">'a'</span>).find(<span class="string">'img'</span>).get(<span class="string">'src'</span>)</span><br><span class="line">        item_index = item.find(class_=<span class="string">''</span>).string  <span class="comment">#</span></span><br><span class="line">        item_name = item.find(class_=<span class="string">'title'</span>).string  <span class="comment">#</span></span><br><span class="line">        item_score = item.find(class_=<span class="string">'rating_num'</span>).string  <span class="comment">#</span></span><br><span class="line">        item_author = item.find(<span class="string">'p'</span>).text</span><br><span class="line">        item_intr = item.find(class_ =<span class="string">'inq'</span>).string  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">'爬取电影：'</span> + item_index + <span class="string">' | '</span> + item_name +<span class="string">' | '</span>  + item_score +<span class="string">' | '</span> + item_intr)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(page)</span>:</span></span><br><span class="line">    url = <span class="string">'https://movie.douban.com/top250?start='</span>+ str(page*<span class="number">25</span>)+<span class="string">'&amp;filter='</span></span><br><span class="line">    html = request_douban(url)</span><br><span class="line">    soup = BeautifulSoup(html)</span><br><span class="line">    save_to_excel(soup)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">2</span>):</span><br><span class="line">        main(i)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">爬取电影：1 | 肖申克的救赎 | 9.7 | 希望让人自由。</span><br><span class="line">爬取电影：2 | 霸王别姬 | 9.6 | 风华绝代。</span><br><span class="line">爬取电影：3 | 阿甘正传 | 9.5 | 一部美国近现代史。</span><br><span class="line">爬取电影：4 | 这个杀手不太冷 | 9.4 | 怪蜀黍和小萝莉不得不说的故事。</span><br><span class="line">爬取电影：5 | 美丽人生 | 9.5 | 最美的谎言。</span><br><span class="line">爬取电影：6 | 泰坦尼克号 | 9.4 | 失去的才是永恒的。 </span><br><span class="line">爬取电影：7 | 千与千寻 | 9.3 | 最好的宫崎骏，最好的久石让。 </span><br><span class="line">爬取电影：8 | 辛德勒的名单 | 9.5 | 拯救一个人，就是拯救整个世界。</span><br><span class="line">爬取电影：9 | 盗梦空间 | 9.3 | 诺兰给了我们一场无法盗取的梦。</span><br><span class="line">爬取电影：10 | 忠犬八公的故事 | 9.4 | 永远都不能忘记你所爱的人。</span><br><span class="line">爬取电影：11 | 海上钢琴师 | 9.3 | 每个人都要走一条自己坚定了的路，</span><br><span class="line">.......</span><br></pre></td></tr></table></figure>

<h2 id="36Kr：24-小时热榜"><a href="#36Kr：24-小时热榜" class="headerlink" title="36Kr：24 小时热榜"></a>36Kr：24 小时热榜</h2><p><a href="https://36kr.com/" target="_blank" rel="noopener">https://36kr.com/</a> 24 小时热榜</p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbuolctv9bj31kb0u01ky.jpg" alt="image-20200213125403637"></p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbupbmdqphj31w00u01kx.jpg" alt="image-20200213131918709"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">print(<span class="string">'from 36Kr...'</span>)</span><br><span class="line">ua = UserAgent()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_douban</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: ua.chrome&#125;</span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="comment">#             response.encoding = 'utf-8'</span></span><br><span class="line">            <span class="comment">#             print(response.text)</span></span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(soup, url)</span>:</span></span><br><span class="line">    <span class="comment">#     print(soup)</span></span><br><span class="line">    list = soup.find(class_=<span class="string">'hotlist-main'</span>).find_all(<span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#     print(list)</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> list:</span><br><span class="line">        <span class="comment">#         print(item)</span></span><br><span class="line">        <span class="comment">#         item_name = item.find(class_='title').string</span></span><br><span class="line">        <span class="comment">#         item_img = item.find('a').find('img').get('src')</span></span><br><span class="line">        <span class="comment">#         item_index = item.find(class_='').string</span></span><br><span class="line">        <span class="comment">#         item_score = item.find(class_='rating_num').string</span></span><br><span class="line">        <span class="comment">#         item_author = item.find('p').text</span></span><br><span class="line">        <span class="comment">#         item_intr = item.find(class_='inq').string</span></span><br><span class="line">        <span class="comment">#         item_intr = item.find(class_ ='inq').string  #</span></span><br><span class="line">        item_url = item.get(<span class="string">'href'</span>)</span><br><span class="line">        item_index = item.text  <span class="comment">#</span></span><br><span class="line">        <span class="comment"># #         print('爬取电影：' + item_index + ' | ' + item_name +' | '  + item_score +' | ' + item_intr)</span></span><br><span class="line">        <span class="comment">#         print(item_index)</span></span><br><span class="line">        <span class="keyword">if</span> item_index:  <span class="comment"># 非空</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            print(<span class="string">'爬取&#123;&#125;: &#123;&#125;|&#123;&#125;'</span>.format(i, item_index, url + item_url))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'https://36kr.com'</span></span><br><span class="line">    html = request_douban(url)</span><br><span class="line">    soup = BeautifulSoup(html)</span><br><span class="line">    save_to_excel(soup, url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">爬取1: 当年鄙视微商的，2020都活成了微商|https://36kr.com/p/5291516</span><br><span class="line">爬取2: 奥斯卡爆款《寄生虫》：你低估了穷人变穷的真相|https://36kr.com/p/5291536</span><br><span class="line">爬取3: 8点1氪丨贾跃亭方回应甘薇索偿40亿元：仍在处理，尚存异议；京东最新股权结构曝光：刘强东持股16.2%，投票权近八成；特斯拉在北美召回1.5万辆Model X|https://36kr.com/p/5291805</span><br><span class="line">爬取4: 最前线 | 疫情持续冲击线下商家，抖音快手鼓励它们上线卖货|https://36kr.com/p/5291683</span><br><span class="line">爬取5: 60 万线下教育机构“自救” | 36氪新风向|https://36kr.com/p/5291373</span><br><span class="line">爬取6: 36氪独家｜「凌笛科技」完成1亿元A+轮融资，服装行业线上协同需求剧增|https://36kr.com/p/5291392</span><br><span class="line">爬取7: 科技神回复 | 甘薇向贾跃亭索赔近40亿，左口袋到右口袋？|https://36kr.com/p/5291789</span><br><span class="line">爬取8: 老乡鸡董事长手撕联名信：至暗时刻，最见一个人的格局|https://36kr.com/p/5291511</span><br><span class="line">爬取9: 氪星晚报 | 新冠肺炎疫情全国新增确诊病例数下降48.2%；甘薇离婚索赔贾跃亭40亿；博瑞医药：今天生产瑞德西韦制剂|https://36kr.com/p/5291734</span><br><span class="line">爬取10: 愿景基金第一家倒闭公司：1亿美金全部打水漂|https://36kr.com/p/5291753</span><br></pre></td></tr></table></figure>

<blockquote>
<p> <code>UserAgent</code>是识别浏览器的一串字符串，相当于浏览器的身份证，在利用爬虫爬取网站数据时，频繁更换<code>UserAgent</code>可以避免触发相应的反爬机制。<code>fake-useragent</code>对频繁更换<code>UserAgent</code>提供了很好的支持，可谓防反扒利器。</p>
</blockquote>
<h2 id="新浪"><a href="#新浪" class="headerlink" title="新浪"></a>新浪</h2><p><a href="https://news.sina.com.cn/china/" target="_blank" rel="noopener">https://news.sina.com.cn/china/</a></p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbus4brqjhj31j50u0kjl.jpg" alt="image-20200213145607132"></p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbus6080v8j31a20pste2.jpg" alt="image-20200213145743738"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">ua = UserAgent()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_douban</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: ua.chrome&#125;</span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            response.encoding = <span class="string">'utf-8'</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#             print(response.text)</span></span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(soup)</span>:</span></span><br><span class="line">    <span class="comment">#     print(soup)</span></span><br><span class="line">    list1 = soup.find(class_=<span class="string">'right-content'</span>).find_all(<span class="string">'li'</span>)</span><br><span class="line">    list2 = soup.find(class_=<span class="string">'news-rank-conb1'</span>).find(class_=<span class="string">'hot-news-ul'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#     print(list2.text)</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> list1:</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        item_img = item.find(<span class="string">'a'</span>).text</span><br><span class="line">        item_url = item.find(<span class="string">'a'</span>).get(<span class="string">'href'</span>)</span><br><span class="line">        <span class="comment">#         item_index = item.find(class_='rankNum').string  #</span></span><br><span class="line">        <span class="comment">#         item_name = item.find(class_='text').string  #</span></span><br><span class="line">        <span class="comment">#         item_score = item.find(class_='rating_num').string  #</span></span><br><span class="line">        <span class="comment">#         item_author = i</span></span><br><span class="line">        <span class="comment">#         item_intr = item.find(class_ ='inq').string  #</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#         print('爬取电影：' + item_index + ' | ' + item_name +' | '  + item_score +' | ' + item_intr)</span></span><br><span class="line">        print(<span class="string">'爬取&#123;&#125;: &#123;&#125; &#123;&#125;'</span>.format(i, item_img, item_url))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'https://news.sina.com.cn/china/'</span></span><br><span class="line">    html = request_douban(url)</span><br><span class="line">    soup = BeautifulSoup(html)</span><br><span class="line">    print(<span class="string">'from新浪...'</span>)</span><br><span class="line">    save_to_excel(soup)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>from新浪…<br>爬取1: 中央赴湖北指导组：应收尽收 刻不容缓 <a href="https://news.sina.com.cn/c/2020-02-08/doc-iimxxste9863647.shtml" target="_blank" rel="noopener">https://news.sina.com.cn/c/2020-02-08/doc-iimxxste9863647.shtml</a><br>爬取2: 王贺胜履新湖北省委常委前 已赴鄂工作多日 <a href="https://news.sina.com.cn/o/2020-02-08/doc-iimxxste9798545.shtml" target="_blank" rel="noopener">https://news.sina.com.cn/o/2020-02-08/doc-iimxxste9798545.shtml</a><br>爬取3: 美媒落井下石翻车 新加坡总理夫妇先后发声挺中国 <a href="https://news.sina.com.cn/c/2020-02-08/doc-iimxxste9855111.shtml" target="_blank" rel="noopener">https://news.sina.com.cn/c/2020-02-08/doc-iimxxste9855111.shtml</a><br>爬取4: 武汉之外疫…..</p>
<h2 id="深圳卫健委每日疫情"><a href="#深圳卫健委每日疫情" class="headerlink" title="深圳卫健委每日疫情"></a>深圳卫健委每日疫情</h2><p>只爬取带“疫情情况”的信息目录：</p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbykx045klj31bv0u0dlt.jpg" alt="image-20200216214906268"></p>
<p><img src="https://tva1.sinaimg.cn/large/0082zybpgy1gbykzclomaj31wi0ryguh.jpg" alt="image-20200216215123059"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line">print(<span class="string">'from 深圳市卫生健康委员会...'</span>)</span><br><span class="line">ua = UserAgent()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_douban</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: ua.chrome&#125;</span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            response.encoding = <span class="string">'utf-8'</span></span><br><span class="line">            <span class="comment"># print(response.text)</span></span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(soup, url)</span>:</span></span><br><span class="line">    <span class="comment">#     print(soup)</span></span><br><span class="line">    list = soup.find(class_=<span class="string">'wendangListC'</span>).find_all(<span class="string">'li'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(list)</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> list:</span><br><span class="line">        <span class="comment">#         print(item)</span></span><br><span class="line">        <span class="comment">#         item_name = item.find(class_='title').string</span></span><br><span class="line">        <span class="comment">#         item_img = item.find('a').find('img').get('src')</span></span><br><span class="line">        item_index0 = item.find(class_=<span class="string">''</span>).string</span><br><span class="line">        <span class="comment">#         item_score = item.find(class_='rating_num').string</span></span><br><span class="line">        <span class="comment">#         item_author = item.find('p').text</span></span><br><span class="line">        <span class="comment">#         item_intr = item.find(class_='inq').string</span></span><br><span class="line">        <span class="comment">#         item_intr = item.find(class_ ='inq').string  #</span></span><br><span class="line">        item_url = item.find(<span class="string">'a'</span>).get(<span class="string">'href'</span>)</span><br><span class="line">        item_txt = item.find(<span class="string">'a'</span>).text  <span class="comment">#</span></span><br><span class="line">        <span class="comment"># #         print('爬取电影：' + item_index + ' | ' + item_name +' | '  + item_score +' | ' + item_intr)</span></span><br><span class="line">        <span class="comment">#         print(item_index)</span></span><br><span class="line">        <span class="keyword">if</span> item_txt <span class="keyword">and</span> <span class="string">'疫情情况'</span> <span class="keyword">in</span> item_txt:  <span class="comment"># 非空 and 过滤</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="comment"># print('爬取&#123;&#125;: &#123;&#125;|&#123;&#125;'.format(i, item_index, url + item_url))</span></span><br><span class="line">            print(<span class="string">'爬取&#123;&#125;: &#123;&#125;|&#123;&#125;'</span>.format(item_index0, item_txt, url[:<span class="number">26</span>] + item_url))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(i)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> i &gt;<span class="number">0</span>:</span><br><span class="line">        url = <span class="string">'http://wjw.sz.gov.cn/yqxx/'</span> + <span class="string">'index_&#123;&#125;.htm'</span>.format(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = <span class="string">'http://wjw.sz.gov.cn/yqxx/'</span></span><br><span class="line">    html = request_douban(url)</span><br><span class="line">    soup = BeautifulSoup(html)</span><br><span class="line">    save_to_excel(soup, url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">15</span>):</span><br><span class="line">        main(i)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">爬取4: 2020年2月16日深圳市新冠肺炎疫情情况|http://wjw.sz.gov.cn/yqxx/./202002/t20200216_19014139.htm</span><br><span class="line">爬取8: 2020年2月15日深圳市新冠肺炎疫情情况|http://wjw.sz.gov.cn/yqxx/./202002/t20200215_19013050.htm</span><br><span class="line">爬取16: 2020年2月14日深圳市新冠肺炎疫情情况|http://wjw.sz.gov.cn/yqxx/./202002/t20200214_19011706.htm</span><br><span class="line">爬取22: 2020年2月13日深圳市新冠肺炎疫情情况|http://wjw.sz.gov.cn/yqxx/./202002/t20200213_19010518.htm</span><br><span class="line">爬取28: 2020年2月12日深圳市新冠肺炎疫情情况|http://wjw.sz.gov.cn/yqxx/./202002/t20200212_19009020.htm</span><br><span class="line">爬取33: 2020年2月11日深圳市新冠肺炎疫情情况|http://wjw.sz.gov.cn/yqxx/./202002/t20200211_19007846.htm</span><br><span class="line">爬取37: 截至2020年2....</span><br></pre></td></tr></table></figure>

<h2 id="书籍爬取"><a href="#书籍爬取" class="headerlink" title="书籍爬取"></a>书籍爬取</h2><p><a href="https://github.com/xdlkc/EpubwSpider" target="_blank" rel="noopener">https://github.com/xdlkc/EpubwSpider</a></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ggve7hpqjqj31r10u01ky.jpg" alt="image-20200718202159879"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://github.com/wistbean/learn_python3_spider" target="_blank" rel="noopener">python爬虫教程从0到1:learn_python3_spider</a></li>
<li></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/02/13/爬虫demo/" data-id="ckor8mdxw004bwnonbd28k439" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/02/20/肺炎预测/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          ⭐️肺炎预测
        
      </div>
    </a>
  
  
    <a href="/2020/01/07/Git学习/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">⭐️Git学习</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CV/">CV</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/网页/">网页</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/随笔/">随笔</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/">Git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bert/">bert</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/">nlp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyhanlp/">pyhanlp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/力扣/">力扣</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/并发/">并发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/底层/">底层</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/搜索-推荐/">搜索/推荐</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/电影/">电影</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编辑/">编辑</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网站/">网站</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网课/">网课</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/规范/">规范</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/视觉/">视觉</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/阅读/">阅读</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Python/" style="font-size: 12px;">Python</a> <a href="/tags/bert/" style="font-size: 10px;">bert</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/nlp/" style="font-size: 18px;">nlp</a> <a href="/tags/pyhanlp/" style="font-size: 10px;">pyhanlp</a> <a href="/tags/力扣/" style="font-size: 12px;">力扣</a> <a href="/tags/大数据/" style="font-size: 10px;">大数据</a> <a href="/tags/并发/" style="font-size: 10px;">并发</a> <a href="/tags/底层/" style="font-size: 18px;">底层</a> <a href="/tags/搜索-推荐/" style="font-size: 10px;">搜索/推荐</a> <a href="/tags/机器学习/" style="font-size: 16px;">机器学习</a> <a href="/tags/深度学习/" style="font-size: 16px;">深度学习</a> <a href="/tags/爬虫/" style="font-size: 10px;">爬虫</a> <a href="/tags/电影/" style="font-size: 10px;">电影</a> <a href="/tags/算法/" style="font-size: 20px;">算法</a> <a href="/tags/编辑/" style="font-size: 10px;">编辑</a> <a href="/tags/网站/" style="font-size: 10px;">网站</a> <a href="/tags/网课/" style="font-size: 14px;">网课</a> <a href="/tags/规范/" style="font-size: 10px;">规范</a> <a href="/tags/视觉/" style="font-size: 14px;">视觉</a> <a href="/tags/阅读/" style="font-size: 14px;">阅读</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2119/10/">October 2119</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2100/01/">January 2100</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">December 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">July 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2000/01/">January 2000</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2119/10/28/待研究问题/">⭐️待研究问题</a>
          </li>
        
          <li>
            <a href="/2100/01/29/网站推荐/">⭐️网站推荐</a>
          </li>
        
          <li>
            <a href="/2021/11/08/copy/">⭐️copy</a>
          </li>
        
          <li>
            <a href="/2021/04/04/数据结构与算法之美（加餐）/">⭐️数据结构与算法之美（加餐）</a>
          </li>
        
          <li>
            <a href="/2021/04/02/数据结构与算法之美（基础篇）/">⭐️数据结构与算法之美（基础篇）</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Dufy<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>